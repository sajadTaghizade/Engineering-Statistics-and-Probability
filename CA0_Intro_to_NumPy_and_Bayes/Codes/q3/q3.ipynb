{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:gold\"> question 3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Various Python library section </span>\n",
    "\n",
    "* import nltk\n",
    "* To read the files and make the necessary changes on the text\n",
    "* sklearn\n",
    "* To use the train_test_split function\n",
    "* which asked us in case of question\n",
    "* numpy\n",
    "* To use the presentations in this library for storing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Answer to part 3 question 3</span>\n",
    "\n",
    "* questions remove stopwords\n",
    "* With this, all prepositions, pronouns, etc. will be removed\n",
    "* RegexpTokenizer\n",
    "* By using these punctuation marks are removed\n",
    "* Porter Stemmer\n",
    "* By using these words, the family becomes one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')\n",
    "tokenizer = RegexpTokenizer(r'\\b[^\\d\\W]+\\b')\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> Without any special changes in emails</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list = []\n",
    "label_list = []\n",
    "\n",
    "with open('emails.csv', 'r') as emails:\n",
    "    for text in emails.readlines()[1:]:\n",
    "        label = int(text.strip()[-1])\n",
    "        label_list.append(label)\n",
    "        texts_list.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Answer to part 3 question 3</span>\n",
    "\n",
    "* Using these changes, we will make the above mentioned changes on the emails\n",
    "* With this, the final accuracy of the work will be higher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list = []\n",
    "label_list = []\n",
    "\n",
    "with open('emails.csv', 'r') as emails:\n",
    "    for text in emails.readlines()[1:]:\n",
    "        text = text.replace('_', '').lower()\n",
    "        label = int(text.strip()[-1])\n",
    "        label_list.append(label)\n",
    "        words = [word for word in tokenizer.tokenize(text) if word not in stop_words]\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "        joined_text = ' '.join(stemmed_words)\n",
    "        texts_list.append(joined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first line of the CountVectorizer function is called \n",
    "* vectorizer.fit_transform \n",
    "* This function creates a dictionary (a list of all the words in the emails for us) and for each email it creates a list of numbers, equivalent to that dictionary of how many times each word appears in this email. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">This code and the code below are for making BOW</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is the manual implementation of the above code, it is not recommended because of the high execution time <span style=\"color:pink\"> :))))))</span>\n",
    "\n",
    "* num_matrix\n",
    "* This is the number matrix of each email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emails.csv', 'r') as emails:\n",
    "    for text in emails.readlines()[1:]:\n",
    "        text = text.replace('_', '').lower()\n",
    "        label = int(text.strip()[-1])\n",
    "        label_list.append(label)\n",
    "        words = [word for word in tokenizer.tokenize(text) if word not in stop_words]\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "        texts_list.append(stemmed_words)\n",
    "        \n",
    "dictionary_list = set(word for text in texts_list for word in text)\n",
    "dictionary_list=sorted(dictionary_list)\n",
    "email_matrix = []\n",
    "for text in texts_list:\n",
    "    row = [text.count(word) for word in dictionary_list]\n",
    "    email_matrix.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This function, which was proposed in the form of the project, is used to separate test and test emails\n",
    "* x's he text of the email\n",
    "* Is it spam or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(X,label_list,test_size=0.9,train_size=0.11,random_state=425)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">To simplify the storage of train emails</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.toarray()\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">To simplify the storage of test emails</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.toarray()\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the probability of spam or not test emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_probability = np.mean(y_train)\n",
    "non_spam_probability = 1 - spam_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this section, it collects all the elements in each column and calculates the number of each word in spams and non-spams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_word_count = np.sum(x_train[y_train == 1], axis=0)\n",
    "non_spam_word_count = np.sum(x_train[y_train == 0], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this case, we find the probability of each word being spam or not, which is equal to the number of each word in spams divided by the total number of spams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_word_probability = (spam_word_count) / (np.sum(spam_word_count))\n",
    "non_spam_word_probability = (non_spam_word_count) / (np.sum(non_spam_word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">part 1 question 3</span>\n",
    "\n",
    "* The bug in the above mode was that if all the words of our test are different from the test mode, you have zero on zero, so we add one to the number of all spam or non-spam values ​​so that it does not become zero.\n",
    "* For the denominator, we add the length of the presentation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_word_probability = (spam_word_count + 1) / (np.sum(spam_word_count) + len(spam_word_count))\n",
    "non_spam_word_probability = (non_spam_word_count + 1) / (np.sum(non_spam_word_count) + len(non_spam_word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Spam prediction function</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(email):\n",
    "    \n",
    "    spam_prob = 0\n",
    "    non_spam_prob = 0\n",
    "    for i in range(len(email)):\n",
    "        if email[i] > 0: \n",
    "            spam_prob += email[i] * spam_word_probability[i]\n",
    "            non_spam_prob += email[i] * non_spam_word_probability[i]\n",
    "    \n",
    "    return 1 if spam_prob > non_spam_prob else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">part 2 question 3</span>\n",
    "\n",
    "### <span style=\"color:blue\">Spam prediction function</span>\n",
    "\n",
    "If the message is long, a large number of multiplications must be done, so we use the logarithm of probabilities to reduce the number of multiplications.\n",
    "\n",
    "This also increases the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(email):\n",
    "    \n",
    "    spam_log_prob = 0\n",
    "    non_spam_log_prob = 0\n",
    "    for i in range(len(email)):\n",
    "        if email[i] > 0: \n",
    "            spam_log_prob += email[i] * np.log(spam_word_probability[i])\n",
    "            non_spam_log_prob += email[i] * np.log(non_spam_word_probability[i])\n",
    "    \n",
    "    return 1 if spam_log_prob > non_spam_log_prob else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:gold\">And finally, do the final test and get the accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [prediction(email) for email in x_test]\n",
    "\n",
    "correct_predict = 0\n",
    "for i in range(len(y_test)):\n",
    "    if predictions[i] == y_test[i]:\n",
    "        correct_predict += 1\n",
    "accuracy = correct_predict / len(y_test)\n",
    "print(f\"final accuracy is: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
